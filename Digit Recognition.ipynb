{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86cc301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten,BatchNormalization\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61fb931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2304c50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of x_train (60000, 28, 28)\n",
      "Dimension of x_test (10000, 28, 28)\n",
      "Dimension of y_test (10000,)\n"
     ]
    }
   ],
   "source": [
    "#our dataset\n",
    "\n",
    "print(\"Dimension of x_train\",x_train.shape)\n",
    "print(\"Dimension of x_test\",x_test.shape)\n",
    "print(\"Dimension of y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ad3b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#sample of our dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[5])\n",
    "plt.show()\n",
    "print(y_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5c8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining some parameters for our model\n",
    "num_classes = 10\n",
    "#as we have 10 classes (0-9) \n",
    "#we need to prdeict one out of 10 which has high probability\n",
    "epochs = 30\n",
    "img_rows = 28 \n",
    "img_cols = 28\n",
    "#as each image is 28 by 28 pixel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e4fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing image \n",
    "x_train =x_train.astype(float)\n",
    "x_train =x_train/255\n",
    "x_test =x_test.astype(float)\n",
    "x_test =x_test/255\n",
    "\n",
    "#y_train =y_train/255\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes = 10, dtype = 'float32')\n",
    "y_test = to_categorical(y_test, num_classes = 10, dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ab0866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if K.image_data_format() =='channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0],1,img_rows,img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0],1,img_rows,img_cols)\n",
    "    input_shape = (1,img_rows,img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0],img_rows,img_cols,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0],img_rows,img_cols,1)\n",
    "    input_shape = (img_rows,img_cols,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a20ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build our model\n",
    "#BY DEFAULT STRIDE IS 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = input_shape))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f2f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model compilation\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ba5c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 11, 11, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 32)          25632     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 6, 6, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6, 6, 32)          0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 4, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 2, 2, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 1, 1, 64)          102464    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 1, 1, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 1, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194,762\n",
      "Trainable params: 194,250\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fb40ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "300/300 [==============================] - 44s 143ms/step - loss: 0.4611 - accuracy: 0.8657 - val_loss: 0.7692 - val_accuracy: 0.7131\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 44s 146ms/step - loss: 0.1130 - accuracy: 0.9696 - val_loss: 0.0535 - val_accuracy: 0.9831\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 43s 145ms/step - loss: 0.0766 - accuracy: 0.9791 - val_loss: 0.0390 - val_accuracy: 0.9882\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 44s 146ms/step - loss: 0.0612 - accuracy: 0.9837 - val_loss: 0.0387 - val_accuracy: 0.9884\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 54s 178ms/step - loss: 0.0510 - accuracy: 0.9863 - val_loss: 0.0362 - val_accuracy: 0.9907\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 48s 161ms/step - loss: 0.0453 - accuracy: 0.9874 - val_loss: 0.0370 - val_accuracy: 0.9892\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 47s 157ms/step - loss: 0.0391 - accuracy: 0.9892 - val_loss: 0.0248 - val_accuracy: 0.9928\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 49s 163ms/step - loss: 0.0349 - accuracy: 0.9905 - val_loss: 0.0387 - val_accuracy: 0.9901\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 45s 151ms/step - loss: 0.0338 - accuracy: 0.9907 - val_loss: 0.0308 - val_accuracy: 0.9914\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 45s 151ms/step - loss: 0.0317 - accuracy: 0.9914 - val_loss: 0.0275 - val_accuracy: 0.9920\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 48s 160ms/step - loss: 0.0284 - accuracy: 0.9921 - val_loss: 0.0347 - val_accuracy: 0.9900\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 45s 150ms/step - loss: 0.0261 - accuracy: 0.9927 - val_loss: 0.0282 - val_accuracy: 0.9914\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 45s 150ms/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 0.0292 - val_accuracy: 0.9919\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 49s 165ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.0383 - val_accuracy: 0.9896\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 48s 161ms/step - loss: 0.0230 - accuracy: 0.9937 - val_loss: 0.0286 - val_accuracy: 0.9930\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 51s 169ms/step - loss: 0.0214 - accuracy: 0.9938 - val_loss: 0.0281 - val_accuracy: 0.9932\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 47s 157ms/step - loss: 0.0203 - accuracy: 0.9943 - val_loss: 0.0256 - val_accuracy: 0.9945\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 51s 169ms/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 0.0244 - val_accuracy: 0.9939\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 55s 185ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0282 - val_accuracy: 0.9924\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 53s 176ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.0257 - val_accuracy: 0.9941\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 56s 186ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.0442 - val_accuracy: 0.9910\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 49s 164ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0277 - val_accuracy: 0.9930\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 53s 177ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.0241 - val_accuracy: 0.9940\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 54s 179ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.0305 - val_accuracy: 0.9928\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 56s 187ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0336 - val_accuracy: 0.9917\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 53s 178ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.0335 - val_accuracy: 0.9930\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 49s 163ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0298 - val_accuracy: 0.9924\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 46s 152ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.0349 - val_accuracy: 0.9927\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 48s 160ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0379 - val_accuracy: 0.9918\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 47s 156ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0273 - val_accuracy: 0.9930\n",
      "Baseline Error: 0.70%\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "model.fit(x_train,y_train,batch_size=200,epochs=epochs,validation_data=(x_test,y_test))\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5daf732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0273 - accuracy: 0.9930\n",
      "Score is : 0.027290359139442444\n",
      "Accuracy : 0.9929999709129333\n"
     ]
    }
   ],
   "source": [
    "score ,acc = model.evaluate(x_test,y_test)\n",
    "print(\"Score is:\",score)\n",
    "print(\"Accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5408e7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save our model\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"models.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c6956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
